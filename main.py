from fastapi import FastAPI, Request, UploadFile, File, Form
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse, RedirectResponse
import os
import shutil
from datetime import date
from typing import Optional # Imported Optional for type hinting if needed

# Import Agent Module
from agent_core import file_to_base64, analyze_audio_to_text, analyze_image_for_context, generate_student_report


UPLOAD_FOLDER = "uploads" 
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

app = FastAPI()

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/uploads", StaticFiles(directory="uploads"), name="uploads")

# Set up template engine
templates = Jinja2Templates(directory="templates")


# --- Core AI Calling Functions ---

def call_glm_api_multimodal_mock(user_input: str, user_name: str, image_b64: str) -> dict:
    """
    Call GLM-4V API (Using text and image input capabilities of GLM-4V)
    Note: This might be legacy code if you are using agent_core.py now, 
    but updated to English just in case.
    """
    if not image_b64:
        return {
            "user_name": user_name,
            "personality": "Image processing failed, multimodal analysis cannot be performed.",
            "career_advice": "Please check the uploaded file format.",
            "hobbies_analysis": "No analysis result.",
            "scores": {"empathy": 50, "resilience": 50, "communication": 50}
        }
    
    # ... (Prompt logic omitted as it's likely replaced by agent_core) ...
    # If this function is still used, ensure the prompt inside is also translated.
    return {}

# --- Route Logic ---

@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request):
    """Home Page"""
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/upload", response_class=HTMLResponse)
async def upload_page(request: Request):
    """Upload Page"""
    return templates.TemplateResponse("upload.html", {"request": request})

# --- analyze route ---
@app.post("/analyze")
async def analyze_data(
    request: Request,
    name: str = Form(...),
    description: str = Form(...),
    avatar: Optional[UploadFile] = File(None),
    photo: UploadFile = File(...),
    audio: UploadFile = File(...)
):
    """
    Receive data, trigger multimodal analysis steps, and generate report.
    """
    # 1. Temporarily store photo and audio files
    photo_path = os.path.join(UPLOAD_FOLDER, photo.filename)
    audio_path = os.path.join(UPLOAD_FOLDER, audio.filename)

    with open(photo_path, "wb") as buffer:
        shutil.copyfileobj(photo.file, buffer)

    with open(audio_path, "wb") as buffer:
        shutil.copyfileobj(audio.file, buffer)
    
    avatar_url = "" # Default empty
    if avatar and avatar.filename:
        avatar_path = os.path.join(UPLOAD_FOLDER, avatar.filename)
        with open(avatar_path, "wb") as buffer:
            shutil.copyfileobj(avatar.file, buffer)
        # Generate accessible URL path
        avatar_url = f"/uploads/{avatar.filename}"

    # 2. Call analysis functions from Agent Core

    # 2.1 Image Analysis (Currently returns None)
    image_analysis_result = analyze_image_for_context(photo_path) 

    # 2.2 Audio Analysis (Currently returns None)
    audio_transcription = analyze_audio_to_text(audio_path)

    # 3. Call Core Agent to generate final report
    report_data = generate_student_report(
        student_name=name,
        teacher_description=description,
        image_analysis_result=image_analysis_result,
        audio_transcription=audio_transcription
    )
    
    # Add avatar_url to report data manually since Agent doesn't generate it
    report_data["avatar_url"] = avatar_url

    # 4. Store and redirect
    app.state.last_report = report_data

    return RedirectResponse(url=f"/report?user={name}", status_code=303)

# --- report route ---
@app.get("/report", response_class=HTMLResponse)
async def report_page(request: Request, user: str = "Student"): # Changed default name
    """
    Result display page, using real data generated by AI
    """
    report = getattr(app.state, 'last_report', None)
    current_date_str = date.today().strftime("%Y-%m-%d")
    
    # Ensure report structure matches new keys (innovation, communication, etc.)
    # Default fallback report in English
    default_report = {
            "user_name": user,
            "personality": "Report failed to load. Please resubmit via the upload page.",
            "learning_advice": "Please check backend logs for API errors.",
            "hobbies_analysis": "No data found.",
            "summary_intro": "Report generation failed, please try again.", 
            "scores": {
                "innovation": 0,    
                "communication": 0, 
                "stability": 0,     
                "drive": 0,         
                "empathy": 0        
            },
            "key_takeaways": ["Report Generation Failed", "Please contact administrator"], 
        }

    if report and report.get("user_name") == user:
        final_report = report
    else:
        final_report = default_report

    return templates.TemplateResponse(
        "report.html", 
        {
            "request": request, 
            "report": final_report,
            "current_date": current_date_str 
        }
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)